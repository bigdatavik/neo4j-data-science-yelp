{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science with Neo4j Using Yelp Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 0: Loading Yelp Data into Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Convert Yelp JSON files to CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "\n",
    "data_dir = '/Users/gtenorio/neo4j_yelp/import/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Convert Business streaming JSON file to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify CSV parameters through custom dialect\n",
    "csv.register_dialect('custom', escapechar='\\\\', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "\n",
    "# Converts the given value to a CSV formatted string\n",
    "def toCSV(value):\n",
    "    # Represent a list of items as a semicolon delimited string\n",
    "    if type(value) == list:\n",
    "        return ';'.join(value)\n",
    "    \n",
    "    # Surround fields with double quotes and handle escape characters\n",
    "    if type(value) == str:\n",
    "        return value.replace('\"', '').replace('\\\\', '')\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "# Converts a dict to a list of CSV formatted strings, optionally restricting\n",
    "# Converted fields by passing in an ordered list of fields\n",
    "def dictToCSV(obj, fields=None):\n",
    "    fields = fields if fields is not None else obj.keys()\n",
    "    return [toCSV(obj[k]) for k in fields]\n",
    "\n",
    "\n",
    "# Takes a JSON file and writes it as a CSV file\n",
    "def convertJSONFileToCSV(json_file, csv_file):\n",
    "    with open(json_file, 'r') as jsonFile, \\\n",
    "         open(csv_file, 'w')  as csvFile:\n",
    "\n",
    "        fields = json.loads(jsonFile.readline()).keys()\n",
    "        writer = csv.writer(csvFile, dialect='custom')\n",
    "        writer.writerow(fields)         # write header\n",
    "\n",
    "        for obj in map(json.loads, jsonFile):\n",
    "            writer.writerow(dictToCSV(obj, fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.7 s, sys: 266 ms, total: 14 s\n",
      "Wall time: 14.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "convertJSONFileToCSV(data_dir + \"business.json\", data_dir + 'business.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Convert User streaming JSON file to CSV.  Create separate Friend data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertUserDataForNeo4jImport(users_file, out_dir):\n",
    "    with open(users_file, 'r') as usersJsonFile, \\\n",
    "         open(os.path.join(out_dir, 'user.csv'), 'w') as usersCSVFile, \\\n",
    "         open(os.path.join(out_dir, 'user_friend.csv'), 'w') as friendsCSVFile:\n",
    "    \n",
    "        userFields = ['user_id','name','yelping_since','review_count','average_stars','fans']\n",
    "        usersWriter = csv.writer(usersCSVFile, dialect='custom')\n",
    "        usersWriter.writerow(userFields)        # write header\n",
    "\n",
    "        friendFields = ['user_id', 'friends']\n",
    "        friendsWriter = csv.writer(friendsCSVFile, dialect='custom')\n",
    "        friendsWriter.writerow(friendFields)    # write header\n",
    "\n",
    "        for obj in map(json.loads, usersJsonFile):\n",
    "            usersWriter.writerow(dictToCSV(obj, userFields))\n",
    "            friendsWriter.writerow(dictToCSV(obj, friendFields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 35s, sys: 2.87 s, total: 1min 38s\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "users_json = data_dir + 'user.json'\n",
    "convertUserDataForNeo4jImport(users_json, data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Convert Review streaming JSON file to CSV.  Create separate REVIEW_OF data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertReviewDataForNeo4jImport(reviews_file, out_dir):\n",
    "    with open(reviews_file, 'r') as reviewsJsonFile, \\\n",
    "         open(os.path.join(out_dir, 'review.csv'), 'w') as reviewsCSVFile, \\\n",
    "         open(os.path.join(out_dir, 'review_user_business.csv'), 'w') as rubCSVFile:\n",
    "          \n",
    "        reviewFields  = ['review_id', 'date', 'stars', 'useful']\n",
    "        reviewsWriter = csv.writer(reviewsCSVFile, dialect='custom')\n",
    "        reviewsWriter.writerow(reviewFields)    # write header\n",
    "\n",
    "        rubFields = ['user_id', 'review_id', 'business_id']\n",
    "        rubWriter = csv.writer(rubCSVFile, dialect='custom')\n",
    "        rubWriter.writerow(rubFields)           # write header\n",
    "\n",
    "        for obj in map(json.loads, reviewsJsonFile):\n",
    "            reviewsWriter.writerow(dictToCSV(obj, reviewFields))\n",
    "            rubWriter.writerow(dictToCSV(obj, rubFields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 24s, sys: 4.93 s, total: 2min 29s\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviews_json = data_dir + 'review.json'\n",
    "convertReviewDataForNeo4jImport(reviews_json, data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Load CSV files into Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# py2neo allows us to work with Neo4j from within Python\n",
    "from py2neo import authenticate, Graph\n",
    "\n",
    "# Set up authentication parameters\n",
    "authenticate(\"localhost:7474\", \"neo4j\", \"neo4jneo4j\") \n",
    "\n",
    "# Connect to authenticated graph database\n",
    "g = Graph(\"http://localhost:7474/db/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<py2neo.database.Cursor at 0x106eb3320>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each time this notebook is run, we start with an empty graph database\n",
    "g.run(\"MATCH (n) DETACH DELETE n;\")    \n",
    "\n",
    "# We drop and recreate our node constraints\n",
    "g.run(\"DROP CONSTRAINT ON (business:Business)   ASSERT business.id   IS UNIQUE;\")\n",
    "g.run(\"DROP CONSTRAINT ON (category:Category)   ASSERT category.name IS UNIQUE;\")\n",
    "g.run(\"DROP CONSTRAINT ON (city:City)           ASSERT city.name     IS UNIQUE;\")\n",
    "g.run(\"DROP CONSTRAINT ON (state:State)         ASSERT state.name    IS UNIQUE;\")\n",
    "g.run(\"DROP CONSTRAINT ON (user:User)           ASSERT user.id       IS UNIQUE;\")\n",
    "g.run(\"DROP CONSTRAINT ON (review:Review)       ASSERT review.id     IS UNIQUE;\")\n",
    "\n",
    "\n",
    "g.run(\"CREATE CONSTRAINT ON (business:Business) ASSERT business.id   IS UNIQUE;\")\n",
    "g.run(\"CREATE CONSTRAINT ON (category:Category) ASSERT category.name IS UNIQUE;\")\n",
    "g.run(\"CREATE CONSTRAINT ON (city:City)         ASSERT city.name     IS UNIQUE;\")\n",
    "g.run(\"CREATE CONSTRAINT ON (state:State)       ASSERT state.name    IS UNIQUE;\")\n",
    "g.run(\"CREATE CONSTRAINT ON (user:User)         ASSERT user.id       IS UNIQUE;\")\n",
    "g.run(\"CREATE CONSTRAINT ON (review:Review)     ASSERT review.id     IS UNIQUE;\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Load Business Data into Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<py2neo.database.Cursor at 0x10862de10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "load_business = \"\"\"\n",
    "\n",
    "    // Load and commit every 50000 records\n",
    "    USING PERIODIC COMMIT 50000 \n",
    "    LOAD CSV WITH HEADERS FROM {input_dir} AS line                      \n",
    "    WITH line \n",
    "        \n",
    "    // Create Business nodes\n",
    "    MERGE (business:Business {id: line.business_id})\n",
    "    SET business.name         = line.name,\n",
    "        business.neighborhood = line.neighborhood,\n",
    "        business.avg_rating   = toFloat(line.stars),\n",
    "        business.num_reviews  = toInteger(line.review_count)\n",
    "        \n",
    "    // Create Category nodes\n",
    "    WITH line, business, split(line.categories, \";\") as cat_list\n",
    "    UNWIND cat_list as cat\n",
    "    MERGE (category:Category {name: cat})\n",
    "    MERGE (business)-[:IN_CATEGORY]->(category)\n",
    "        \n",
    "    // Create City and State nodes\n",
    "    MERGE (city:City {name: line.city})\n",
    "    MERGE (state:State {name: line.state})\n",
    "    MERGE (business)-[:IN_CITY]->(city)\n",
    "    MERGE (business)-[:IN_STATE]->(state)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "g.run(load_business, input_dir='file:///business.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Load User Data into Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 ms, sys: 7.33 ms, total: 17.8 ms\n",
      "Wall time: 4min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "load_user = \"\"\"\n",
    "        \n",
    "    // Load and commit every 50000 records\n",
    "    USING PERIODIC COMMIT 50000 \n",
    "    LOAD CSV WITH HEADERS FROM {input_dir} AS line                      \n",
    "    WITH line \n",
    "        \n",
    "    // Create User nodes\n",
    "    MERGE (user:User {id: line.user_id})\n",
    "    SET user.name              = line.name,\n",
    "        user.yelping_since     = line.yelping_since,\n",
    "        user.num_reviews       = toInteger(line.review_count),\n",
    "        user.avg_review_rating = toFloat(line.average_stars),\n",
    "        user.num_fans          = toInteger(line.fans)\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "g.run(load_user, input_dir='file:///user.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 165 ms, sys: 107 ms, total: 272 ms\n",
      "Wall time: 1h 26min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create FRIENDS_WITH relationship between Users\n",
    "load_friend = \"\"\"\n",
    "\n",
    "    // Load and commit every 50000 records\n",
    "    USING PERIODIC COMMIT 50000 \n",
    "    LOAD CSV WITH HEADERS FROM {input_dir} AS line                      \n",
    "    WITH line  \n",
    "        \n",
    "    // Only load Users already in the graph\n",
    "    MATCH (user:User {id: line.user_id})\n",
    "        \n",
    "    // Create FRIENDS_WITH relationship\n",
    "    WITH line, user, split(line.friends, \";\") as friend_list\n",
    "    UNWIND friend_list as friend\n",
    "    MATCH (f:User {id: friend})\n",
    "    MERGE (user)-[:FRIENDS_WITH]->(f)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "g.run(load_friend, input_dir='file:///user_friend.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### C. Load Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.5 ms, sys: 27.5 ms, total: 64.9 ms\n",
      "Wall time: 27min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# First pass will create Review nodes only, not relationships\n",
    "load_review = \"\"\"\n",
    "        \n",
    "    // Load and commit every 50000 records\n",
    "    USING PERIODIC COMMIT 50000 \n",
    "    LOAD CSV WITH HEADERS FROM {input_dir} AS line                      \n",
    "    WITH line \n",
    "        \n",
    "    // Create Review nodes\n",
    "    MERGE (review:Review {id: line.review_id})\n",
    "    SET review.date                   = line.date,\n",
    "        review.rating                 = toInteger(line.stars),\n",
    "        review.useful_votes_received  = toInteger(line.useful)\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "g.run(load_review, input_dir='file:///review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.1 ms, sys: 32.2 ms, total: 78.3 ms\n",
      "Wall time: 21min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Second pass creates relationships\n",
    "load_review_rel = \"\"\"\n",
    "        \n",
    "    // Load and commit every 50000 records\n",
    "    USING PERIODIC COMMIT 50000 \n",
    "    LOAD CSV WITH HEADERS FROM {input_dir} AS line                      \n",
    "    WITH line \n",
    "        \n",
    "    // Only care about Users and Businesses already in the graph\n",
    "    MATCH (review:Review     {id:line.review_id})\n",
    "    MATCH (user:User         {id:line.user_id})\n",
    "    MATCH (business:Business {id:line.business_id})\n",
    "               \n",
    "    MERGE (user)-[:WROTE]->(review)\n",
    "    MERGE (review)-[:REVIEW_OF]->(business)\n",
    " \n",
    "    \"\"\"\n",
    "\n",
    "g.run(load_review_rel, input_dir='file:///review_user_business.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
