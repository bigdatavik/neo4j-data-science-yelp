{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science with Neo4j Using Yelp Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 0: Loading Yelp Data into Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Convert Yelp JSON files to CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "\n",
    "data_dir = '/Users/gtenorio/neo4j_yelp/import/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Convert Business streaming JSON file to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify CSV parameters through custom dialect\n",
    "csv.register_dialect('custom', escapechar='\\\\', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "\n",
    "# Converts the given value to a CSV formatted string\n",
    "def toCSV(value):\n",
    "    # Represent a list of items as a semicolon delimited string\n",
    "    if type(value) == list:\n",
    "        return ';'.join(value)\n",
    "    \n",
    "    # Surround fields with double quotes and handle escape characters\n",
    "    if type(value) == str:\n",
    "        return value.replace('\"', '').replace('\\\\', '')\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "# Converts a dict to a list of CSV formatted strings, optionally restricting\n",
    "# Converted fields by passing in an ordered list of fields\n",
    "def dictToCSV(obj, fields=None):\n",
    "    fields = fields if fields is not None else obj.keys()\n",
    "    return [toCSV(obj[k]) for k in fields]\n",
    "\n",
    "\n",
    "# Takes a JSON file and writes it as a CSV file\n",
    "def convertJSONFileToCSV(json_file, csv_file):\n",
    "    with open(json_file, 'r') as jsonFile, \\\n",
    "         open(csv_file, 'w')  as csvFile:\n",
    "\n",
    "        fields = json.loads(jsonFile.readline()).keys()\n",
    "        writer = csv.writer(csvFile, dialect='custom')\n",
    "        writer.writerow(fields)         # write header\n",
    "\n",
    "        for obj in map(json.loads, jsonFile):\n",
    "            writer.writerow(dictToCSV(obj, fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.8 s, sys: 275 ms, total: 13.1 s\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "convertJSONFileToCSV(data_dir + \"business.json\", data_dir + 'business.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Convert User streaming JSON file to CSV.  Create separate Friend data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertUserDataForNeo4jImport(users_file, out_dir):\n",
    "    with open(users_file, 'r') as usersJsonFile, \\\n",
    "         open(os.path.join(out_dir, 'user.csv'), 'w') as usersCSVFile, \\\n",
    "         open(os.path.join(out_dir, 'user_friend.csv'), 'w') as friendsCSVFile:\n",
    "    \n",
    "        userFields = ['user_id','name','yelping_since','review_count','average_stars','fans']\n",
    "        usersWriter = csv.writer(usersCSVFile, dialect='custom')\n",
    "        usersWriter.writerow(userFields)        # write header\n",
    "\n",
    "        friendFields = ['user_id', 'friends']\n",
    "        friendsWriter = csv.writer(friendsCSVFile, dialect='custom')\n",
    "        friendsWriter.writerow(friendFields)    # write header\n",
    "\n",
    "        for obj in map(json.loads, usersJsonFile):\n",
    "            usersWriter.writerow(dictToCSV(obj, userFields))\n",
    "            friendsWriter.writerow(dictToCSV(obj, friendFields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 45s, sys: 3.88 s, total: 1min 49s\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "users_json = data_dir + 'user.json'\n",
    "convertUserDataForNeo4jImport(users_json, data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Convert Review streaming JSON file to CSV.  Create separate REVIEW_OF data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertReviewDataForNeo4jImport(reviews_file, out_dir):\n",
    "    with open(reviews_file, 'r') as reviewsJsonFile, \\\n",
    "         open(os.path.join(out_dir, 'review.csv'), 'w') as reviewsCSVFile, \\\n",
    "         open(os.path.join(out_dir, 'review_user_business.csv'), 'w') as rubCSVFile:\n",
    "          \n",
    "        reviewFields  = ['review_id', 'date', 'stars', 'useful']\n",
    "        reviewsWriter = csv.writer(reviewsCSVFile, dialect='custom')\n",
    "        reviewsWriter.writerow(reviewFields)    # write header\n",
    "\n",
    "        rubFields = ['user_id', 'review_id', 'business_id']\n",
    "        rubWriter = csv.writer(rubCSVFile, dialect='custom')\n",
    "        rubWriter.writerow(rubFields)           # write header\n",
    "\n",
    "        for obj in map(json.loads, reviewsJsonFile):\n",
    "            reviewsWriter.writerow(dictToCSV(obj, reviewFields))\n",
    "            rubWriter.writerow(dictToCSV(obj, rubFields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 27s, sys: 5.69 s, total: 2min 32s\n",
      "Wall time: 2min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviews_json = data_dir + 'review.json'\n",
    "convertReviewDataForNeo4jImport(reviews_json, data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Load CSV files into Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j.v1 import GraphDatabase, basic_auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=basic_auth(\"neo4j\", \"neo4jneo4j\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.06 ms, sys: 2.35 ms, total: 4.41 ms\n",
      "Wall time: 92.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Each time this notebook is run, we start with an empty graph database\n",
    "with driver.session() as session:\n",
    "    session.run(\"MATCH (n) DETACH DELETE n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.8 ms, sys: 6.56 ms, total: 22.3 ms\n",
      "Wall time: 105 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Drop constraints from our database\n",
    "with driver.session() as session:\n",
    "    session.run(\"DROP CONSTRAINT ON (business:Business)   ASSERT business.id   IS UNIQUE\")\n",
    "    session.run(\"DROP CONSTRAINT ON (category:Category)   ASSERT category.name IS UNIQUE\")\n",
    "    session.run(\"DROP CONSTRAINT ON (city:City)           ASSERT city.name     IS UNIQUE\")\n",
    "    session.run(\"DROP CONSTRAINT ON (state:State)         ASSERT state.name    IS UNIQUE\")\n",
    "    session.run(\"DROP CONSTRAINT ON (user:User)           ASSERT user.id       IS UNIQUE\")\n",
    "    session.run(\"DROP CONSTRAINT ON (review:Review)       ASSERT review.id     IS UNIQUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.65 ms, sys: 2.45 ms, total: 6.1 ms\n",
      "Wall time: 143 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create constraints in our database\n",
    "with driver.session() as session:\n",
    "    session.run(\"CREATE CONSTRAINT ON (business:Business)   ASSERT business.id   IS UNIQUE\")\n",
    "    session.run(\"CREATE CONSTRAINT ON (category:Category)   ASSERT category.name IS UNIQUE\")\n",
    "    session.run(\"CREATE CONSTRAINT ON (city:City)           ASSERT city.name     IS UNIQUE\")\n",
    "    session.run(\"CREATE CONSTRAINT ON (state:State)         ASSERT state.name    IS UNIQUE\")\n",
    "    session.run(\"CREATE CONSTRAINT ON (user:User)           ASSERT user.id       IS UNIQUE\")\n",
    "    session.run(\"CREATE CONSTRAINT ON (review:Review)       ASSERT review.id     IS UNIQUE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Load Business Data into Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 202 ms, sys: 115 ms, total: 317 ms\n",
      "Wall time: 1h 46min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "load_business = \"\"\"\\\n",
    "    // Load and commit every 50000 records\n",
    "    USING PERIODIC COMMIT 50000 \n",
    "    LOAD CSV WITH HEADERS FROM {input_dir} AS line                      \n",
    "    WITH line \n",
    "    // Create Business nodes\n",
    "    MERGE (business:Business {id: line.business_id})\n",
    "    SET business.name         = line.name,\n",
    "        business.neighborhood = line.neighborhood,\n",
    "        business.avg_rating   = toFloat(line.stars),\n",
    "        business.num_reviews  = toInteger(line.review_count)\n",
    "    // Create Category nodes\n",
    "    WITH line, business, split(line.categories, \";\") as cat_list\n",
    "    UNWIND cat_list as cat\n",
    "    MERGE (category:Category {name: cat})\n",
    "    MERGE (business)-[:IN_CATEGORY]->(category)\n",
    "    // Create City and State nodes\n",
    "    MERGE (city:City {name: line.city})\n",
    "    MERGE (state:State {name: line.state})\n",
    "    MERGE (business)-[:IN_CITY]->(city)\n",
    "    MERGE (business)-[:IN_STATE]->(state)\n",
    "    \"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(load_business, input_dir='file:///business.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Load User Data into Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 ms, sys: 9.68 ms, total: 20.3 ms\n",
      "Wall time: 4min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "load_user = \"\"\"\\\n",
    "    // Load and commit every 50000 records\n",
    "    USING PERIODIC COMMIT 50000 \n",
    "    LOAD CSV WITH HEADERS FROM {input_dir} AS line                      \n",
    "    WITH line \n",
    "    // Create User nodes\n",
    "    MERGE (user:User {id: line.user_id})\n",
    "    SET user.name              = line.name,\n",
    "        user.yelping_since     = line.yelping_since,\n",
    "        user.num_reviews       = toInteger(line.review_count),\n",
    "        user.avg_review_rating = toFloat(line.average_stars),\n",
    "        user.num_fans          = toInteger(line.fans)    \n",
    "    \"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(load_user, input_dir='file:///user.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 214 ms, sys: 130 ms, total: 344 ms\n",
      "Wall time: 7h 11min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create FRIENDS_WITH relationship between Users\n",
    "load_friend = \"\"\"\\\n",
    "    // Load and commit every 50000 records\n",
    "    USING PERIODIC COMMIT 50000 \n",
    "    LOAD CSV WITH HEADERS FROM {input_dir} AS line                      \n",
    "    WITH line  \n",
    "    // Only load Users already in the graph\n",
    "    MATCH (user:User {id: line.user_id})\n",
    "    // Create FRIENDS_WITH relationship\n",
    "    WITH line, user, split(line.friends, \";\") as friend_list\n",
    "    UNWIND friend_list as friend\n",
    "    MATCH (f:User {id: friend})\n",
    "    MERGE (user)-[:FRIENDS_WITH]->(f)\n",
    "    \"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(load_friend, input_dir='file:///user_friend.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### C. Load Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.5 ms, sys: 25.2 ms, total: 61.7 ms\n",
      "Wall time: 17min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# First pass will create Review nodes only, not relationships\n",
    "load_review = \"\"\"\\\n",
    "    // Load and commit every 50000 records\n",
    "    USING PERIODIC COMMIT 50000 \n",
    "    LOAD CSV WITH HEADERS FROM {input_dir} AS line                      \n",
    "    WITH line \n",
    "    // Create Review nodes\n",
    "    MERGE (review:Review {id: line.review_id})\n",
    "    SET review.date                   = line.date,\n",
    "        review.rating                 = toInteger(line.stars),\n",
    "        review.useful_votes_received  = toInteger(line.useful)    \n",
    "    \"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(load_review, input_dir='file:///review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.2 ms, sys: 35.9 ms, total: 87.1 ms\n",
      "Wall time: 25min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Second pass creates relationships\n",
    "load_review_rel = \"\"\"\\\n",
    "    // Load and commit every 50000 records\n",
    "    USING PERIODIC COMMIT 50000 \n",
    "    LOAD CSV WITH HEADERS FROM {input_dir} AS line                      \n",
    "    WITH line \n",
    "    // Only care about Users and Businesses already in the graph\n",
    "    MATCH (review:Review     {id:line.review_id})\n",
    "    MATCH (user:User         {id:line.user_id})\n",
    "    MATCH (business:Business {id:line.business_id})\n",
    "    MERGE (user)-[:WROTE]->(review)\n",
    "    MERGE (review)-[:REVIEW_OF]->(business)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.run(load_review_rel, input_dir='file:///review_user_business.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
